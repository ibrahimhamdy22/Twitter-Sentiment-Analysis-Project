{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The input data needs to be preprocessed using the `pad_sequences` function.\\nAlso, the code is using the `glorot_uniform` initializer to initialize the weights of the neural network.\\nFinally, the code sets up the environment to display the plots inline using %matplotlib inline.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings #Import warnings module to handle warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning) #Filter DeprecationWarning to ignore the warnings\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.models import Model ,Sequential \n",
    "from keras.layers import Embedding ,Dense ,Dropout , LSTM ,Input ,Activation , Bidirectional ,GlobalMaxPool1D #Import various types of layers from keras.layers module\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences #Import pad_sequences function from tensorflow.keras.preprocessing.sequence module\n",
    "from keras.initializers import glorot_uniform\n",
    "%matplotlib inline\n",
    "\n",
    "\"\"\" The input data needs to be preprocessed using the `pad_sequences` function.\n",
    "Also, the code is using the `glorot_uniform` initializer to initialize the weights of the neural network.\n",
    "Finally, the code sets up the environment to display the plots inline using %matplotlib inline.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22760\n",
      "22513\n"
     ]
    }
   ],
   "source": [
    "# Load the data \n",
    "neg_train=pd.read_csv('train_Arabic_tweets_negative_20190413.tsv',sep='\\t')\n",
    "neg_train.columns=['sentiment','text']\n",
    "len(neg_train)\n",
    "pos_train=pd.read_csv('train_Arabic_tweets_positive_20190413.tsv',sep='\\t')\n",
    "pos_train.columns=['sentiment','text']\n",
    "print(len(pos_train))\n",
    "print(len(neg_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45273"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate data\n",
    "data = pd.concat([neg_train, pos_train])\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>pos</td>\n",
       "      <td>๐น ุงูุฑุงุจุฑ ุฌููู ููู ูู ููุชุดููุง ๐ฅ - ุงุจุฑูู ุ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>pos</td>\n",
       "      <td>โ ูุงู ุงูุฅูุงู ุงุจู ุงูููู ุฑุญูู ุงููู : ูู ุงุนุชุงุฏ โง ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21375</th>\n",
       "      <td>neg</td>\n",
       "      <td>ูฒููุณ ูู ุงูุนูุจ ุงู ุชุญูุธ ูู ุงูุฃุบุงูู .. ูุชูุฑุฑ ููุณ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13848</th>\n",
       "      <td>pos</td>\n",
       "      <td>:40 ุงููุถุน ุงูุงู ุงูุญูุฏููู .. ูุงู ุงูุจุงุก ุนู ุงุตุงุจุงุช...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9552</th>\n",
       "      <td>pos</td>\n",
       "      <td>ููู ุฃุญูุงูุง ููุฃููุง ุฃุญูุง ุงููุงุณ ุฌููุนุง ุทููุฉ ุนูุฑูุง ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text\n",
       "7997        pos           ๐น ุงูุฑุงุจุฑ ุฌููู ููู ูู ููุชุดููุง ๐ฅ - ุงุจุฑูู ุ\n",
       "1656        pos  โ ูุงู ุงูุฅูุงู ุงุจู ุงูููู ุฑุญูู ุงููู : ูู ุงุนุชุงุฏ โง ...\n",
       "21375       neg  ูฒููุณ ูู ุงูุนูุจ ุงู ุชุญูุธ ูู ุงูุฃุบุงูู .. ูุชูุฑุฑ ููุณ ...\n",
       "13848       pos  :40 ุงููุถุน ุงูุงู ุงูุญูุฏููู .. ูุงู ุงูุจุงุก ุนู ุงุตุงุจุงุช...\n",
       "9552        pos  ููู ุฃุญูุงูุง ููุฃููุง ุฃุญูุง ุงููุงุณ ุฌููุนุง ุทููุฉ ุนูุฑูุง ..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## shufle data\n",
    "from sklearn.utils import shuffle\n",
    "shuffled_data = shuffle(data)\n",
    "shuffled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert pos to 1 and neg to 0\n",
    "shuffled_data['sentiment']=shuffled_data['sentiment'].apply(lambda x: 1 if x =='pos' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>1</td>\n",
       "      <td>๐น ุงูุฑุงุจุฑ ุฌููู ููู ูู ููุชุดููุง ๐ฅ - ุงุจุฑูู ุ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>1</td>\n",
       "      <td>โ ูุงู ุงูุฅูุงู ุงุจู ุงูููู ุฑุญูู ุงููู : ูู ุงุนุชุงุฏ โง ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21375</th>\n",
       "      <td>0</td>\n",
       "      <td>ูฒููุณ ูู ุงูุนูุจ ุงู ุชุญูุธ ูู ุงูุฃุบุงูู .. ูุชูุฑุฑ ููุณ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13848</th>\n",
       "      <td>1</td>\n",
       "      <td>:40 ุงููุถุน ุงูุงู ุงูุญูุฏููู .. ูุงู ุงูุจุงุก ุนู ุงุตุงุจุงุช...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9552</th>\n",
       "      <td>1</td>\n",
       "      <td>ููู ุฃุญูุงูุง ููุฃููุง ุฃุญูุง ุงููุงุณ ุฌููุนุง ุทููุฉ ุนูุฑูุง ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                               text\n",
       "7997           1           ๐น ุงูุฑุงุจุฑ ุฌููู ููู ูู ููุชุดููุง ๐ฅ - ุงุจุฑูู ุ\n",
       "1656           1  โ ูุงู ุงูุฅูุงู ุงุจู ุงูููู ุฑุญูู ุงููู : ูู ุงุนุชุงุฏ โง ...\n",
       "21375          0  ูฒููุณ ูู ุงูุนูุจ ุงู ุชุญูุธ ูู ุงูุฃุบุงูู .. ูุชูุฑุฑ ููุณ ...\n",
       "13848          1  :40 ุงููุถุน ุงูุงู ุงูุญูุฏููู .. ูุงู ุงูุจุงุก ุนู ุงุตุงุจุงุช...\n",
       "9552           1  ููู ุฃุญูุงูุง ููุฃููุง ุฃุญูุง ุงููุงุณ ุฌููุนุง ุทููุฉ ุนูุฑูุง ..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-trained Word2Vec model\n",
    "from gensim.models import KeyedVectors\n",
    "def load_w2v(file_path,binary):\n",
    "    return KeyedVectors.load_word2vec_format(file_path,binary=binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = load_w2v(\"wiki.ar.vec\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610977\n"
     ]
    }
   ],
   "source": [
    "print(len(w2v.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 85\n",
    "max_num_words = len(w2v.index_to_key)\n",
    "embedding_dim = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "[('ุุญุณู', 0.6795670390129089), ('ุฃุจูุญุณู', 0.6792263388633728), ('#ุญุณู', 0.6771580576896667), ('ูุญุณู', 0.6517007350921631), ('ูุญุณู', 0.6505534648895264), ('\\u200fุญุณู', 0.6446623206138611), ('ูุญุณู', 0.6202388405799866), ('ุนุจุฏุงูุญุณู', 0.6161733865737915), ('ุจูุญุณู', 0.6157496571540833), ('ุฏ/ุญุณู', 0.6062546372413635)]\n"
     ]
    }
   ],
   "source": [
    "sample=w2v['ุญุณู']\n",
    "print(sample.shape)\n",
    "print(w2v.most_similar('ุญุณู'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ุ', 'ุก', 'ุกู', 'ุข', 'ุขุจ', 'ุขุฐุงุฑ', 'ุขุถ', 'ุขู', 'ุขูููู', 'ุขูุงุก', 'ุขููุง', 'ุขู', 'ุขูุงู', 'ุขูู', 'ุขูู', 'ุฃ', 'ุฃุจุฏุง', 'ุฃุจุฑูู', 'ุฃุจู', 'ุฃุจู', 'ุฃุฌู', 'ุฃุฌูุน', 'ุฃุญุฏ', 'ุฃุฎุจุฑ', 'ุฃุฎุฐ', 'ุฃุฎู', 'ุฃุฎู', 'ุฃุฑุจุน', 'ุฃุฑุจุนุงุก', 'ุฃุฑุจุนุฉ', 'ุฃุฑุจุนูุฆุฉ', 'ุฃุฑุจุนูุงุฆุฉ', 'ุฃุฑู', 'ุฃุณูู', 'ุฃุตุจุญ', 'ุฃุตูุง', 'ุฃุถุญู', 'ุฃุทุนู', 'ุฃุนุทู', 'ุฃุนูู', 'ุฃุบุณุทุณ', 'ุฃูุฑูู', 'ุฃูุนู ุจู', 'ุฃููู', 'ุฃูุจู', 'ุฃูุชูุจุฑ', 'ุฃู', 'ุฃูุง', 'ุฃูู', 'ุฃููู', 'ุฃู', 'ุฃูุง', 'ุฃูุงู', 'ุฃูุงูู', 'ุฃูุงููู', 'ุฃูุฏ', 'ุฃูุณ', 'ุฃูุณู', 'ุฃููุง', 'ุฃู', 'ุฃูุง', 'ุฃูุจุฃ', 'ุฃูุช', 'ุฃูุชู', 'ุฃูุชูุง', 'ุฃูุชู', 'ุฃูุชู', 'ุฃูุดุฃ', 'ุฃูู', 'ุฃููู', 'ุฃููู', 'ุฃููุง', 'ุฃู', 'ุฃูุช', 'ุฃูุดู', 'ุฃูู', 'ุฃููุฆู', 'ุฃููุงุก', 'ุฃููุงูู', 'ุฃูููู', 'ุฃู', 'ุฃู', 'ุฃูุง', 'ุฃูุงุฑ', 'ุฃูุถุง', 'ุฃูููู', 'ุฃูู', 'ุฃูู', 'ุฃููุงู', 'ุฃูููู', 'ุค', 'ุฅุญุฏู', 'ุฅุฐ', 'ุฅุฐุง', 'ุฅุฐุงู', 'ุฅุฐูุง', 'ุฅุฐู', 'ุฅุฒุงุก', 'ุฅูู', 'ุฅูู', 'ุฅูููู', 'ุฅููููุง', 'ุฅููููู', 'ุฅูููู', 'ุฅูููููู', 'ุฅููุง', 'ุฅููุง', 'ุฅู', 'ุฅููู', 'ุฅู', 'ุฅูุงู', 'ุฅูุงูู', 'ุฅูุงููุง', 'ุฅูุงูู', 'ุฅูุงูุง', 'ุฅูุงู', 'ุฅูุงูุง', 'ุฅูุงูู', 'ุฅูุงููุง', 'ุฅูุงูู', 'ุฅูุงู', 'ุฅููู', 'ุฆ', 'ุง', 'ุง?', 'ุง?ู', 'ุงุงูุง', 'ุงุงูุชู', 'ุงุจุชุฏุฃ', 'ุงุจูู', 'ุงุชุฎุฐ', 'ุงุซุฑ', 'ุงุซูุง', 'ุงุซูุงู', 'ุงุซูู', 'ุงุซููู', 'ุงุฌู', 'ุงุญุฏ', 'ุงุฎุฑู', 'ุงุฎูููู', 'ุงุฐุง', 'ุงุฑุจุนุฉ', 'ุงุฑุจุนูู', 'ุงุฑุจุนูู', 'ุงุฑุชุฏู', 'ุงุณุชุญุงู', 'ุงุตุจุญ', 'ุงุถุญู', 'ุงุทุงุฑ', 'ุงุนุงุฏุฉ', 'ุงุนููุช', 'ุงู', 'ุงูุซุฑ', 'ุงูุฏ', 'ุงูุขู', 'ุงูุฃูุงุก', 'ุงูุฃูู', 'ุงูุง', 'ุงูุงุฎูุฑุฉ', 'ุงูุงู', 'ุงูุงูู', 'ุงูุงููู', 'ุงูุชู', 'ุงูุชู', 'ุงูุซุงูู', 'ุงูุซุงููุฉ', 'ุงูุญุงูู', 'ุงูุฐุงุชู', 'ุงูุฐู', 'ุงูุฐู', 'ุงูุฐูู', 'ุงูุณุงุจู', 'ุงูู', 'ุงููุงุชู', 'ุงููุชุงู', 'ุงููุชูุง', 'ุงููุชูู', 'ุงููุฐุงู', 'ุงููุฐูู', 'ุงูููุงุชู', 'ุงููุงุถู', 'ุงูููุจู', 'ุงูููุช', 'ุงูู', 'ุงูู', 'ุงููู', 'ุงูููุง', 'ุงูููู', 'ุงูุง', 'ุงูุงู', 'ุงูุณ', 'ุงูุณู', 'ุงู', 'ุงูุจุฑู', 'ุงูููุจ', 'ุงูู', 'ุงููุง', 'ุงู', 'ุงูู', 'ุงู', 'ุงูุงุฑ', 'ุงูุงู', 'ุงูุถุง', 'ุจ', 'ุจุคุณุง', 'ุจุฅู', 'ุจุฆุณ', 'ุจุงุก', 'ุจุงุช', 'ุจุงุณู', 'ุจุงู', 'ุจุฎู', 'ุจุฏ', 'ุจุฏูุง', 'ุจุฑุณ', 'ุจุณุจุจ', 'ุจุณู', 'ุจุดูู', 'ุจุถุน', 'ุจุทุขู', 'ุจุนุฏ', 'ุจุนุฏุง', 'ุจุนุถ', 'ุจุบุชุฉ', 'ุจู', 'ุจูู', 'ุจู', 'ุจู', 'ุจูุง', 'ุจูุฐุง', 'ุจูุฏ', 'ุจูู', 'ุจูุณู', 'ุจููููู', 'ุฉ', 'ุช', 'ุชุงุก', 'ุชุงุฑุฉ', 'ุชุงุณุน', 'ุชุงูู', 'ุชุงููู', 'ุชุจุฏูู', 'ุชุฌุงู', 'ุชุญุช', 'ุชุญููู', 'ุชุฎุฐ', 'ุชุฑู', 'ุชุณุน', 'ุชุณุนุฉ', 'ุชุณุนูุฆุฉ', 'ุชุณุนูุงุฆุฉ', 'ุชุณุนูู', 'ุชุณุนูู', 'ุชุดุฑูู', 'ุชุนุณุง', 'ุชุนูููู', 'ุชูุนูุงู', 'ุชูุนููู', 'ุชูุนููู', 'ุชููู', 'ุชููุงุก', 'ุชูู', 'ุชู', 'ุชููุฒ', 'ุชููู', 'ุชููููู', 'ุชูู', 'ุชูู', 'ุซ', 'ุซุงุก', 'ุซุงูุซ', 'ุซุงูู', 'ุซุงู', 'ุซุงูู', 'ุซูุงุซ', 'ุซูุงุซุงุก', 'ุซูุงุซุฉ', 'ุซูุงุซูุฆุฉ', 'ุซูุงุซูุงุฆุฉ', 'ุซูุงุซูู', 'ุซูุงุซูู', 'ุซู', 'ุซูุงู', 'ุซูุงููุฆุฉ', 'ุซูุงููู', 'ุซูุงูู', 'ุซูุงููุฉ', 'ุซูุงููู', 'ุซูููุฆุฉ', 'ุซููู', 'ุซูู', 'ุซููุฉ', 'ุฌ', 'ุฌุงููู', 'ุฌุฏุง', 'ุฌุนู', 'ุฌูู', 'ุฌูุนุฉ', 'ุฌููุน', 'ุฌููู', 'ุฌูุงู', 'ุฌููููุฉ', 'ุฌูุฑ', 'ุฌูู', 'ุญ', 'ุญุงุก', 'ุญุงุฏู', 'ุญุงุฑ', 'ุญุงุดุง', 'ุญุงููุง', 'ุญุงู', 'ุญุจุฐุง', 'ุญุจูุจ', 'ุญุชู', 'ุญุฌุง', 'ุญุฏูุซ', 'ุญุฑู', 'ุญุฒูุฑุงู', 'ุญุณุจ', 'ุญูุง', 'ุญูุฏุง', 'ุญูู', 'ุญูู', 'ุญูุงูู', 'ุญูู', 'ุญูุซ', 'ุญูุซูุง', 'ุญูู', 'ุญููู', 'ุญูุฐุงุฑู', 'ุฎ', 'ุฎุงุก', 'ุฎุงุตุฉ', 'ุฎุงู', 'ุฎุงูุณ', 'ุฎุจููุฑ', 'ุฎูุง', 'ุฎูุงูุง', 'ุฎูุงู', 'ุฎูู', 'ุฎูุณ', 'ุฎูุณุฉ', 'ุฎูุณูุฆุฉ', 'ุฎูุณูุงุฆุฉ', 'ุฎูุณูู', 'ุฎูุณูู', 'ุฎููุณ', 'ุฏ', 'ุฏุงู', 'ุฏุฑูู', 'ุฏุฑู', 'ุฏูุงููู', 'ุฏููุงุฑ', 'ุฏูู', 'ุฏููู', 'ุฏูุณูุจุฑ', 'ุฏููุงุฑ', 'ุฐ', 'ุฐุง', 'ุฐุงุช', 'ุฐุงู', 'ุฐุงู', 'ุฐุงูู', 'ุฐุงูู', 'ุฐูู', 'ุฐูุจ', 'ุฐู', 'ุฐูุช', 'ุฐููู', 'ุฐููููู', 'ุฐูู', 'ุฐูู', 'ุฑ', 'ุฑุฃู', 'ุฑุงุก', 'ุฑุงุจุน', 'ุฑุงุญ', 'ุฑุฌุน', 'ุฑุฒู', 'ุฑููุฏู', 'ุฑูุงู', 'ุฑูุซ', 'ุฑูุจูู', 'ุฒ', 'ุฒุงู', 'ุฒุนู', 'ุฒูุฏ', 'ุฒูุงุฑุฉ', 'ุณ', 'ุณุงุก', 'ุณุงุจุน', 'ุณุงุฏุณ', 'ุณุจุช', 'ุณุจุชูุจุฑ', 'ุณุจุญุงู', 'ุณุจุน', 'ุณุจุนุฉ', 'ุณุจุนูุฆุฉ', 'ุณุจุนูุงุฆุฉ', 'ุณุจุนูู', 'ุณุจุนูู', 'ุณุช', 'ุณุชุฉ', 'ุณุชููู', 'ุณุชูุฆุฉ', 'ุณุชูุงุฆุฉ', 'ุณุชูู', 'ุณุชูู', 'ุณุญูุง', 'ุณุฑุง', 'ุณุฑุนุงู', 'ุณูู', 'ุณูุนุง', 'ุณูุฉ', 'ุณูุชูู', 'ุณููุงุช', 'ุณูู', 'ุณูู', 'ุณูู', 'ุด', 'ุดุจุงุท', 'ุดุจู', 'ุดุชุงูู', 'ุดุฎุตุง', 'ุดุฑุน', 'ุดูุงู', 'ุดููู', 'ุดูู', 'ุดูุชููุงูู', 'ุต', 'ุตุงุฏ', 'ุตุงุฑ', 'ุตุจุงุญ', 'ุตุจุฑ', 'ุตุจุฑุง', 'ุตุฏูุง', 'ุตุฑุงุญุฉ', 'ุตูุฑ', 'ุตูู', 'ุตูู', 'ุถ', 'ุถุงุฏ', 'ุถุญูุฉ', 'ุถุฏ', 'ุถูู', 'ุท', 'ุทุงุก', 'ุทุงู', 'ุทุงููุง', 'ุทุฑุง', 'ุทูู', 'ุทูู', 'ุธ', 'ุธุงุก', 'ุธู', 'ุธูู', 'ุธููู', 'ุน', 'ุนุงุฏ', 'ุนุงุดุฑ', 'ุนุงู', 'ุนุงูุง', 'ุนุงูุฉ', 'ุนุฌุจุง', 'ุนุฏุง', 'ุนุฏุฉ', 'ุนุฏุฏ', 'ุนุฏู', 'ุนุฏูู', 'ุนุณู', 'ุนุดุฑ', 'ุนุดุฑุฉ', 'ุนุดุฑูู', 'ุนุดุฑูู', 'ุนู', 'ุนูู', 'ุนูู', 'ุนูู', 'ุนูู', 'ุนููู', 'ุนููู', 'ุนูููุง', 'ุนููู', 'ุนู', 'ุนูุฏ', 'ุนูุฏูุง', 'ุนูู', 'ุนููุง', 'ุนูุถ', 'ุนูุงูุง', 'ุนูู', 'ุนูุฏูุณู', 'ุบ', 'ุบุงุฏุฑ', 'ุบุงูุจุง', 'ุบุฏุง', 'ุบุฏุงุฉ', 'ุบูุฑ', 'ุบูู', 'ู', 'ู', 'ูุฅู', 'ูุงุก', 'ูุงู', 'ูุงูู', 'ูุจุฑุงูุฑ', 'ูุฑุงุฏู', 'ูุถูุง', 'ููุฏ', 'ููุท', 'ููุงู', 'ููุงู', 'ููุณ', 'ููู', 'ูู', 'ููู', 'ูู', 'ูู', 'ูููุฑู', 'ููู', 'ูููุง', 'ู', 'ูุงุทุจุฉ', 'ูุงู', 'ูุงู', 'ูุงู', 'ูุจู', 'ูุฏ', 'ูุฑุด', 'ูุทู', 'ูููุง', 'ููุฉ', 'ู', 'ูุฃู', 'ูุฃูู', 'ูุฃูู', 'ูุฃููู', 'ูุงุฏ', 'ูุงู', 'ูุงู', 'ูุงูุช', 'ูุงููู', 'ูุซูุฑุง', 'ูุฐุง', 'ูุฐูู', 'ูุฑุจ', 'ูุณุง', 'ูู', 'ููุชุง', 'ููู', 'ููููุง', 'ููููุง', 'ูู', 'ููุง', 'ูู', 'ูู', 'ููุช', 'ููู', 'ููููุง', 'ููุฎ', 'ู', 'ูุฃู', 'ูุง', 'ูุง ุณููุง', 'ูุงุช', 'ูุงุฒุงู', 'ูุงุณููุง', 'ูุงู', 'ูุงูุฒุงู', 'ูุจูู', 'ูุฏู', 'ูุฏู', 'ูุฏู', 'ูุฐูู', 'ูุนู', 'ูุนููู', 'ูุนูุฑ', 'ููุงุก', 'ููู', 'ูููู', 'ููููู', 'ููุงูู', 'ูู', 'ููุง', 'ูููุง', 'ูู', 'ูู', 'ููุง', 'ููุฐุง', 'ููู', 'ูู', 'ูููุงูุฉ', 'ูููุง', 'ูููุง', 'ููุช', 'ููุฑุฉ', 'ููุณ', 'ููุณุจ', 'ู', 'ูุฆุฉ', 'ูุฆุชุงู', 'ูุง', 'ูุง ุฃูุนูู', 'ูุง ุงููู', 'ูุง ุจุฑุญ', 'ูุงุฆุฉ', 'ูุงุงููู', 'ูุงุจุฑุญ', 'ูุงุฏุงู', 'ูุงุฐุง', 'ูุงุฑุณ', 'ูุงุฒุงู', 'ูุงูุชุฆ', 'ูุงู', 'ูุงูุฒุงู', 'ูุงูู', 'ูุชู', 'ูุซู', 'ูุฐ', 'ูุฑูุฉ', 'ูุณุงุก', 'ูุน', 'ูุนุงุฐ', 'ูุนู', 'ูุนูุง', 'ููุงุจู', 'ููุงููู', 'ููุงูููุง', 'ููุงูููู', 'ููุงููู', 'ูููุงุฑ', 'ูููู', 'ููููู', 'ููุง', 'ูู', 'ููุฐ', 'ููู', 'ูููุง', 'ูู', 'ูููุง', 'ููู', 'ู', 'ูุง', 'ูุจููุง', 'ูุญู', 'ูุญู', 'ูุนู', 'ููุณ', 'ููุณู', 'ููุงูุฉ', 'ููููุจุฑ', 'ููู', 'ููุณุงู', 'ููู', 'ููุฎู', 'ููู', 'ู', 'ูุคูุงุก', 'ูุง', 'ูุงุก', 'ูุงูู', 'ูุจู', 'ูุฐุง', 'ูุฐู', 'ูู', 'ูููุฉ', 'ููู', 'ูููุง', 'ูู', 'ููุง', 'ููุฒุฉ', 'ูู', 'ููุง', 'ููุงู', 'ููุงูู', 'ูู', 'ูู', 'ููุง', 'ูููุงุช', 'ูููุง', 'ููุคูุงุก', 'ููุงุชุงูู', 'ููุงุชููููู', 'ููุงุชูู', 'ููุงุชูู', 'ููุฌู', 'ููุฐุง', 'ููุฐุงูู', 'ููุฐููููู', 'ููุฐูู', 'ููุฐูู', 'ูููููุงุช', 'ู', 'ู6', 'ูุฃุจู', 'ูุฃู', 'ูุง', 'ูุงุญุฏ', 'ูุงุถุงู', 'ูุงุถุงูุช', 'ูุงูุฏ', 'ูุงูุชู', 'ูุงูุฐู', 'ูุงู', 'ูุงูุงู', 'ูุงู', 'ูุงูุถุญ', 'ูุจูู', 'ูุซู', 'ูุฌุฏ', 'ูุฑุงุกูู', 'ูุฑุฏ', 'ูุนูู', 'ููู', 'ููุงู', 'ููุงูุช', 'ููุฏ', 'ููู', 'ููุงู', 'ููุงูุช', 'ููุง', 'ููุงูุฒุงู', 'ูููู', 'ููู', 'ููู', 'ูููุณ', 'ููุน', 'ููู', 'ููุจ', 'ููุฐุง', 'ููู', 'ููู', 'ูููู', 'ููุดูููุงูู', 'ู', 'ู', 'ูุงุก', 'ููุนูุงู', 'ููุนููู', 'ูููู', 'ููู', 'ูููู', 'ูููู', 'ูู', 'ููุงูุฑ', 'ููุงู', 'ููุฑู', 'ููููู', 'ููู', 'ููููู', 'ูุฃููุงู']\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import glob\n",
    "import codecs\n",
    "from keras.preprocessing.text import Tokenizer ,text_to_word_sequence\n",
    "def get_stop_words():\n",
    "    path='list.txt'\n",
    "    stop_words = []\n",
    "    with codecs.open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfile:\n",
    "        stop_words = myfile.readlines()\n",
    "    stop_words = [word.strip() for word in stop_words]\n",
    "    return stop_words\n",
    "stop_words=get_stop_words()\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove stop words from text\n",
    "shuffled_data['text']=shuffled_data['text'].apply(lambda x : [item for item in x.split() if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20096    [ูุฎุจุฑููู, :, ุณุงุฑ, ุงูุฏุฑุจ, ูุตู, ูุฎุจุฑู, ุจุงููุตุฉ, ุง...\n",
       "6140     [ุจููุงุณุจุฉ, ููุฒ, ุงูููุงู, .., ๐, ุณุญุจ, ุขูููู, XR๐ฑ,...\n",
       "777      [ุงูุฎูุฑ, ูุฌูุงุนูุ, ุชูุฑูุจุง, ุงุญูู, ูุตูุญู, ุงูุง, ุดูุช...\n",
       "10959    [ุงูููุงู, ููุชุตุฑ, .., ุจุนูุฏ, ูุณุชูุงู, !, ุฅูุฏุงุฑ, ุบุฑ...\n",
       "14928    [๐, ููุชุจ, ููุชููุณ, ุญุฑูููุง, ูููู, ูุชุนุงูู, ุฃูุฌุงุนู...\n",
       "                               ...                        \n",
       "7607                                         [ุบุฑุช, ูุงุณ, ๐]\n",
       "13890    [ุจููุงุณุจุฉ, ููุฒ, ุงูููุงู, .., ๐, ุณุญุจ, ุขูููู, XR๐ฑ,...\n",
       "2798     [ุณุฃููุง, ุญูููุง:, ููุงุฐุง, ุชุฑุฏ, ูุณูุฆูู, ููุ, ูุฑุฏ, ...\n",
       "14024    [ููุจู, ูุณุชุญู, ุงููุฑุญ, ูุงุณุชูุฏุนู, ุงููู, ูุงุทูุฆู, ๐น...\n",
       "8103        [ูุฑุฌุน, ูููู, ุงูุนุงูู, ูููุงู, ูุงุณ, ูููู, ูุทู, ๐]\n",
       "Name: text, Length: 45273, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83180\n"
     ]
    }
   ],
   "source": [
    "## tokenize data\n",
    "# It easily vectorize text data by converting words into integer indices, and it also provides several options for handling text preprocessing tasks such as filtering out stop words, lowercasing text, and more.\n",
    "tokenizer= Tokenizer()\n",
    "tokenizer.fit_on_texts(shuffled_data['text']) # This step updates the tokenizer's internal vocabulary based on the frequency of the words in the text corpus.\n",
    "word_index=tokenizer.word_index # This line creates a dictionary of word-to-index mappings based on the updated vocabulary of the tokenizer. \n",
    "vocab_size=len(word_index)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences=tokenizer.texts_to_sequences(shuffled_data['text'])\n",
    "train_paded_sequences=pad_sequences(train_sequences,maxlen=max_sequence_length,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45273"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_paded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_paded_sequences,valid_paded_sequences,y_train,y_valid=train_test_split(train_paded_sequences,shuffled_data['sentiment'].values,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((max_num_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if word in w2v.key_to_index:\n",
    "        embedding_matrix[i] = w2v.get_vector(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build model\n",
    "sentence_indices = Input(shape=(max_sequence_length,),dtype='int32')\n",
    "embedding_layer = Embedding(vocab_size+1 , embeding_dim,  input_length=max_sequence_length)\n",
    "embeddings = embedding_layer(sentence_indices)   \n",
    "X = LSTM(60, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(embeddings)\n",
    "X = GlobalMaxPool1D()(X)\n",
    "X = Dropout(0.2)(X)\n",
    "X = Dense(128)(X)\n",
    "X = Activation(\"relu\")(X)\n",
    "X = Dropout(0.2)(X)\n",
    "X = Dense(512)(X)\n",
    "X = Activation(\"relu\")(X)\n",
    "X = Dropout(0.2)(X)\n",
    "X = Dense(1)(X)\n",
    "X = Activation('softmax')(X)\n",
    "model = Model(inputs=sentence_indices,outputs=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1132/1132 [==============================] - 419s 363ms/step - loss: 0.2338 - accuracy: 0.5045 - val_loss: 0.1342 - val_accuracy: 0.4956\n",
      "Epoch 2/10\n",
      "1132/1132 [==============================] - 386s 341ms/step - loss: 0.0900 - accuracy: 0.5045 - val_loss: 0.1321 - val_accuracy: 0.4956\n",
      "Epoch 3/10\n",
      "1132/1132 [==============================] - 377s 333ms/step - loss: 0.0565 - accuracy: 0.5045 - val_loss: 0.1201 - val_accuracy: 0.4956\n",
      "Epoch 4/10\n",
      "1132/1132 [==============================] - 382s 337ms/step - loss: 0.0421 - accuracy: 0.5045 - val_loss: 0.1374 - val_accuracy: 0.4956\n",
      "Epoch 5/10\n",
      "1132/1132 [==============================] - 392s 347ms/step - loss: 0.0353 - accuracy: 0.5045 - val_loss: 0.1627 - val_accuracy: 0.4956\n",
      "Epoch 6/10\n",
      "1132/1132 [==============================] - 387s 342ms/step - loss: 0.0301 - accuracy: 0.5045 - val_loss: 0.1668 - val_accuracy: 0.4956\n",
      "Epoch 7/10\n",
      "1132/1132 [==============================] - 380s 336ms/step - loss: 0.0276 - accuracy: 0.5045 - val_loss: 0.1877 - val_accuracy: 0.4956\n",
      "Epoch 8/10\n",
      "1132/1132 [==============================] - 393s 347ms/step - loss: 0.0270 - accuracy: 0.5045 - val_loss: 0.1896 - val_accuracy: 0.4956\n",
      "Epoch 9/10\n",
      "1132/1132 [==============================] - 380s 336ms/step - loss: 0.0249 - accuracy: 0.5045 - val_loss: 0.2014 - val_accuracy: 0.4956\n",
      "Epoch 10/10\n",
      "1132/1132 [==============================] - 373s 330ms/step - loss: 0.0242 - accuracy: 0.5045 - val_loss: 0.2418 - val_accuracy: 0.4956\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_paded_sequences, y_train, batch_size=32, epochs=10, validation_data=(valid_paded_sequences, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
